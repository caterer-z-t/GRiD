{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9eef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "from typing import Optional, Dict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf25e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cram_path=\"/nas/longleaf/home/catererz/epi/lpa/cram/NWD340659.b38.irc.v1.cram\"\n",
    "crai_path=\"/nas/longleaf/home/catererz/epi/lpa/cram/NWD340659.b38.irc.v1.cram.crai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0236f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_cram(\n",
    "    input_cram: str,\n",
    "    output_bam: str,\n",
    "    region: Dict[str, int],\n",
    "    input_crai: Optional[str] = None,\n",
    "    reference_fasta: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Subset a CRAM file to a specific region and save as BAM.\n",
    "\n",
    "    :param input_cram: Path to the input CRAM file.\n",
    "    :param output_bam: Path to the output BAM file.\n",
    "    :param region: Dictionary with 'chrom', 'start', and 'end' keys.\n",
    "    :param input_crai: Path to the CRAM index file (optional).\n",
    "    :param reference_fasta: Path to the reference FASTA file (optional).\n",
    "    :return: Path to the created BAM file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build kwargs for AlignmentFile depending on what's provided\n",
    "    open_kwargs = {\"reference_filename\": reference_fasta} if reference_fasta else {}\n",
    "    if input_crai:\n",
    "        open_kwargs[\"index_filename\"] = input_crai\n",
    "\n",
    "    # Open input CRAM\n",
    "    infile = pysam.AlignmentFile(input_cram, \"rc\", **open_kwargs)\n",
    "\n",
    "    # Create output BAM file\n",
    "    outfile = pysam.AlignmentFile(output_bam, \"wb\", header=infile.header)\n",
    "\n",
    "    # Fetch and write reads in specified region\n",
    "    for read in infile.fetch(region[\"chrom\"], region[\"start\"], region[\"end\"]):\n",
    "        outfile.write(read)\n",
    "\n",
    "    infile.close()\n",
    "    outfile.close()\n",
    "\n",
    "    # Index the new BAM file\n",
    "    pysam.index(output_bam)\n",
    "\n",
    "    return output_bam\n",
    "\n",
    "# subset_cram(\n",
    "#     input_cram=\"input.cram\",\n",
    "#     output_bam=\"subset.bam\",\n",
    "#     region={\"chrom\": \"chr6\", \"start\": 159900000, \"end\": 161100000},\n",
    "#     reference_fasta=\"hg38.fa\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c2b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No reference: 4.38s, 19858072 bytes\n",
      "With reference: 3.79s, 19858072 bytes\n"
     ]
    }
   ],
   "source": [
    "# Time the runs\n",
    "start = time.time()\n",
    "subset_cram(\n",
    "    input_cram=cram_path, \n",
    "    output_bam=\"/nas/longleaf/home/catererz/epi/lpa/cram/no_ref.bam\", \n",
    "    region={\"chrom\": \"chr6\", \"start\": 159900000, \"end\": 161100000}\n",
    ")\n",
    "\n",
    "no_ref_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "subset_cram(\n",
    "    input_cram=cram_path, \n",
    "    output_bam=\"/nas/longleaf/home/catererz/epi/lpa/cram/with_ref.bam\", \n",
    "    region={\"chrom\": \"chr6\", \"start\": 159900000, \"end\": 161100000},\n",
    "    reference_fasta=\"/nas/longleaf/home/catererz/epi/lpa/cram/hg38.fa\"\n",
    ")\n",
    "with_ref_time = time.time() - start\n",
    "\n",
    "# Compare BAM sizes\n",
    "no_ref_size = os.path.getsize(\"/nas/longleaf/home/catererz/epi/lpa/cram/no_ref.bam\")\n",
    "with_ref_size = os.path.getsize(\"/nas/longleaf/home/catererz/epi/lpa/cram/with_ref.bam\")\n",
    "\n",
    "print(f\"  No reference: {no_ref_time:.2f}s, {no_ref_size} bytes\")\n",
    "print(f\"With reference: {with_ref_time:.2f}s, {with_ref_size} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4ec9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a05083d",
   "metadata": {},
   "source": [
    "## **1. Cohort Filtering & QC**\n",
    "\n",
    "* **Primary dataset**: UK Biobank exome sequencing + SNP array.\n",
    "* **Ancestry & relatedness filters**\n",
    "\n",
    "  * Start with White British for discovery.\n",
    "  * Remove PC outliers (>6 SD from mean of any of first 10 PCs).\n",
    "  * Remove one from each ≤2nd-degree related pair (kinship >0.0884), keeping individuals with relevant phenotype measurements.\n",
    "  * Use expanded European-ancestry sample for follow-up.\n",
    "* **Phenotype of interest**: Serum lipoprotein(a) (Lp(a)), with special handling for values outside reportable range (crop to 3.7 or 190 nmol/L, keep binary info).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. VNTR Identification & Genotyping (KIV-2 Specific)**\n",
    "\n",
    "1. **Identify KIV-2 repeat**\n",
    "\n",
    "   * Custom algorithm to find large multi-kb repeats in GRCh38 (could not rely on read-spanning approaches because UKB WES has 76 bp reads).\n",
    "2. **Estimate diploid VNTR length** from exome depth-of-coverage:\n",
    "\n",
    "   * Count reads overlapping KIV-2.\n",
    "   * Normalize per-sample coverage using 200 most similar exomes to reduce technical bias.\n",
    "3. **Phase & impute VNTR allele lengths**:\n",
    "\n",
    "   * Statistical phasing with surrounding SNP haplotypes.\n",
    "   * Impute phased VNTR allele lengths into full UKB cohort.\n",
    "4. **Genotype PSVs (Paralogous Sequence Variants) within KIV-2**:\n",
    "\n",
    "   * Catalog within-repeat sequence variation from exome data.\n",
    "   * Estimate PSV copy numbers and incorporate into phasing/imputation.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Fine-Mapping & Likely-Causal Variant Identification**\n",
    "\n",
    "* Combine:\n",
    "\n",
    "  * **Phased KIV-2 allele lengths**\n",
    "  * **PSVs in and near KIV-2 exons**\n",
    "  * **SNPs/indels in *LPA***\n",
    "* Special “effective haploid” fine-mapping:\n",
    "\n",
    "  * Use carriers of null/very-low Lp(a) alleles to isolate effects of variants on single chromosomes.\n",
    "* Identify **\\~23 likely-causal LPA variants** (protein-altering or 5’UTR) via stepwise conditional analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Predictive Modeling of Lp(a)**\n",
    "\n",
    "* Build an allele-level model:\n",
    "\n",
    "  * Baseline curve: nonlinear relationship between KIV-2 length and Lp(a) in absence of modifiers.\n",
    "  * Add multiplicative effects of causal SNPs/PSVs on that baseline per haplotype.\n",
    "* Compare models:\n",
    "\n",
    "  * **KIV-2 length only**\n",
    "  * **Length + causal variants (linear model)**\n",
    "  * **Full nonlinear haplotype model** (final).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Association Testing**\n",
    "\n",
    "* For KIV-2 VNTR & Lp(a):\n",
    "\n",
    "  * Association analysis in BOLT-LMM with standard covariates.\n",
    "  * Fine-mapping with FINEMAP and SuSiE to confirm causality (PIP=1 for KIV-2 in Lp(a) model).\n",
    "* Downstream: logistic regression for myocardial infarction and T2D risk using genetically predicted Lp(a).\n",
    "\n",
    "---\n",
    "\n",
    "## **6. PRS Construction (Your Goal)**\n",
    "\n",
    "To make a VNTR-informed PRS from their framework:\n",
    "\n",
    "1. **Genotype & phase KIV-2 VNTR lengths** in your target cohort (follow their depth normalization, phasing, imputation strategy).\n",
    "2. **Genotype key LPA causal variants** (the 23 they identify, or updated list if new fine-mapping is done).\n",
    "3. **Apply the allele-level predictive model**:\n",
    "\n",
    "   * For each haplotype, start with baseline Lp(a) predicted from KIV-2 length.\n",
    "   * Modify baseline by multiplicative effects of causal SNPs/PSVs present on same haplotype.\n",
    "   * Sum the two haplotype contributions to get predicted Lp(a).\n",
    "4. **Use predicted Lp(a)** (or residuals if modeling other phenotypes) as the PRS or as part of a multi-trait PRS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d6ae4b",
   "metadata": {},
   "source": [
    "**VNTRwrap LPA-specific Workflow**\n",
    "\n",
    "**Main Pipeline (generic VNTR handling before LPA branch)**\n",
    "\n",
    "1. **Count Reads**\n",
    "\n",
    "   * *Software:* `samtools` 1.17\n",
    "   * Input: BAM files, VNTR coordinates (from Mukamel TRF)\n",
    "   * Output: counts of reads overlapping VNTR regions.\n",
    "\n",
    "2. **Generate Depth Profiles**\n",
    "\n",
    "   * *Software:* `mosdepth` v0.2.5\n",
    "   * Input: BAM files + GRCh38 reference\n",
    "   * Output: per-1kb-window read depth.\n",
    "\n",
    "3. **Normalize Depth Profiles**\n",
    "\n",
    "   * *Software:* C++ normalization script (`g++`, Boost 1.58)\n",
    "   * Input: Repeat mask BED, mosdepth outputs\n",
    "   * Goal: remove sample-to-sample technical biases.\n",
    "\n",
    "4. **Find Neighbors**\n",
    "\n",
    "   * *Software:* C++ neighbor-finding script\n",
    "   * Input: normalized depth profiles\n",
    "   * Output: list of most similar samples (for later normalization).\n",
    "\n",
    "---\n",
    "\n",
    "**LPA-specific Branch**\n",
    "Runs **after Step 4** (skips main pipeline Step 5).\n",
    "\n",
    "**LPA-1. Extract Reference**\n",
    "\n",
    "* *Software:* `bedtools` 2.30\n",
    "* Input: hg38/hg37 FASTA + BED of KIV-2 region\n",
    "* Output: fasta of KIV-2 sequence.\n",
    "\n",
    "**LPA-2. Realign**\n",
    "\n",
    "* *Software:* C++ realignment script, `samtools`\n",
    "* Input: KIV-2 fasta, BAMs\n",
    "* Output: counts for exon 1A and 1B only.\n",
    "\n",
    "**LPA-3. Compute Diploid Copy Number**\n",
    "\n",
    "* *Software:* bash script\n",
    "* Input: realignment counts + neighbor list\n",
    "* Method: top 200 neighbors, normalize within-individual & across neighbors.\n",
    "* Output: per-sample diploid CN for exon1A, exon1B, exon1B\\_KIV3, exon1B\\_notKIV3.\n",
    "\n",
    "**LPA-4. (Deprecated)**\n",
    "\n",
    "* PSV-based subtyping + phasing (Mukamel did this; your PI skipped).\n",
    "\n",
    "**LPA-5. Estimate Total KIV-2 CN**\n",
    "\n",
    "* *Software:* Python (pandas)\n",
    "* Formula: `KIV_CN = 34.9 * exon1A + 5.2 * exon1B - 1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4030c8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
